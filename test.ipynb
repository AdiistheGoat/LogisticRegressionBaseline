{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2a5228",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from collections import defaultdict\n",
    "import pickle as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e98a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('papermodeldata(in).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba64a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns) -5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ttd'].isnull().any()\n",
    "df['fold'].isnull().any()\n",
    "df['time'].isnull().any()\n",
    "df['y'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels = df['y'].groupby(df['y']).count()\n",
    "count_labels[1]/count_labels[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89199aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VitalID'].groupby(df['VitalID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead = df[df['y'] == 1]\n",
    "df_alive = df[df['y'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alive['VitalID'].groupby(df_alive['VitalID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead['VitalID'].groupby(df_dead['VitalID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_folds = df.groupby(['fold','y']).size()\n",
    "first = None\n",
    "second = None\n",
    "count = 0\n",
    "for i in count_folds:\n",
    "    count+=1\n",
    "    if not(first):\n",
    "        first = i\n",
    "    else:\n",
    "        second = i\n",
    "\n",
    "    if(count==2):\n",
    "        count = 0\n",
    "        print((second/first)*100)\n",
    "        first = None \n",
    "        second = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29727d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(['VitalID', 'time','fold','ttd'], axis=1)\n",
    "df_na_dropped = df_dropped.dropna()\n",
    "df_dead = df_dropped[df_dropped['y'] == 1]\n",
    "df_alive = df_dropped[df_dropped['y'] == 0]\n",
    "df_dead_na_dropped = df_na_dropped[df_na_dropped['y'] == 1]\n",
    "df_alive_na_dropped = df_na_dropped[df_na_dropped['y'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba51166",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((len(df_dead)- len(df_dead_na_dropped)) /len(df_dead)) * 100)\n",
    "print(((len(df_alive) - len(df_alive_na_dropped)) /len(df_alive))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde131e2",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the y seprate \n",
    "# remove nan values \n",
    "# remove duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ttd is there , that means the baby is eventually going to die..\n",
    "# if ttd<=days , put y = 1\n",
    "# if ttd>days  , put y =0\n",
    "def format_y(no_of_days,ttd,y_values):\n",
    "    for index in range(len(ttd)):\n",
    "        if(ttd[index]<=no_of_days):\n",
    "            y_values[index] = 1\n",
    "        else:\n",
    "            y_values[index] = 0\n",
    "    return y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33871e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "def winsorize_col(column):\n",
    "    return winsorize(column, limits=(0.001, .001))\n",
    "\n",
    "def winsorize_df(df):\n",
    "    return df.apply(winsorize_col,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96072373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df,days):\n",
    "    ttd = df['ttd']\n",
    "    y_arr = df['y']\n",
    "    y_arr = format_y(days,ttd,y_arr)\n",
    "    df['y'] = y_arr\n",
    "    # change the y column in the df to the y_arr\n",
    "\n",
    "    # we only care if the trainign data colun values contain NaN values \n",
    "    df_drop_col = df.drop(['VitalID','ttd','time'], axis=1)\n",
    "    df_drop_col_dup = df_drop_col.drop_duplicates()\n",
    "    df_drop_col_dup_na = df_drop_col_dup.dropna()\n",
    "\n",
    "    y_arr = df_drop_col_dup_na['y']\n",
    "    fold_arr = df_drop_col_dup_na['fold']\n",
    "\n",
    "    df_drop_col_dup_na.drop(['y','fold'], axis=1,inplace=True)\n",
    "    df = winsorize_df(df_drop_col_dup_na)\n",
    "    return df,fold_arr,y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basics = [ \"VitalID\",\"time\",\"fold\",\"ttd\",\"y\"]\n",
    "\n",
    "Demographics = ['bwt', 'ega', 'male', 'apgar5']\n",
    "\n",
    "HR = ['HR.SB.MotifTwo.diff.uu', 'HR.SB.MotifTwo.diff.uuu','HR.ST.LocalExtrema.l25.diffmaxabsmin', 'HR.std','HR.SB.MotifThree.diffquant.hhhh',\n",
    "       'HR.EX.MovingThreshold.a0.25.b0.1.meanqover', 'HR.DN.cv.3','HR.SB.MotifTwo.iqr.ddd','HR.SY.StdNthDer.5','HR.ST.LocalExtrema.l25.maxmaxmed', 'HR.SY.StdNthDer.17', 'HR.Quantile.99', 'HR.FC.Suprise.tstat',\n",
    "       'HR.SB.MotifThree.quantile.hhhh','HR.EX.MovingThreshold.a0.25.b0.05.meanqover','HR.PH.Walkerrunningvar...sw.meanabsdiff', 'HR.CO.tc3.1..denom', 'HR.mean',\n",
    "       'HR.skew2','HR.SB.TransitionMatrix23.sumdiagcov','HR.ST.LocalExtrema.n100.minabsmin', 'HR.kurt2', 'HR.MF.arfit.sbc.7'\n",
    "       ]\n",
    "\n",
    "SPO2 = [ 'SP.EX.MovingThreshold.a0.25.b0.1.meanqover', 'SP.EX.MovingThreshold.a1.b0.25.iqrq', 'SP.PH.Walkerbiasprop.0.1..0.5..sw.meanabsdiff',\n",
    "'SP.EX.MovingThreshold.a0.25.b0.1.maxq', 'SP.PH.Walkerprop.0.9..w.std', 'SP.skew2','SP.SB.MotifTwo.diff.dduu','SP.DN.RemovePointsmin.0.2.mean',\n",
    "'SP.PH.Walkermomentum.2..sw.stdrat','SP.CO.tc3.1..denom','SP.mean','SP.kurt2', 'SP.SB.MotifThree.diffquant.hhh','SP.SB.MotifTwo.mean.dddd',\n",
    "'SP.AutoCorr.lag.4','SP.SB.TransitionMatrix41.ondiag', 'SP.SB.MotifThree.quantile.baaa','SP.std', 'SP.SB.TransitionMatrix21.T10', 'SP.SB.BinaryMethod.iqr.pstretch1'\n",
    ",'SP.PH.Walkerprop.0.9..sw.stdrat','SP.MF.arfit.sbc.7','SP.SB.TransitionMatrix22.mineig','SP.ST.LocalExtrema.n100.minabsmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_dfs(df):\n",
    "    df_hr = df[Basics + HR]\n",
    "    df_spo2 = df[Basics + SPO2]\n",
    "    df_demographics = df[Basics + Demographics]\n",
    "    df_hr_spo2 = df[Basics + HR + SPO2] \n",
    "    df_hr_spo2_demographics = df[Basics + HR + SPO2 + Demographics]\n",
    "    return [df_hr,df_spo2,df_demographics,df_hr_spo2,df_hr_spo2_demographics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_hr,df_spo2,df_demographics,df_hr_spo2,df_hr_spo2_demographics] = create_diff_dfs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e05dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fbc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while (curr_no_of_features(variable) >= 5)\n",
    "    # for the different no of folds(variable)\n",
    "        # take only that fold dataset from the df(variable) and its corresponding y for validation \n",
    "        # the rest of the data will be used to train the model\n",
    "\n",
    "        # fit the model \n",
    "        # do the inference on the hold out set \n",
    "        # store the cv accuracy score \n",
    "\n",
    "        # call the permuation_importance function and provide the fitted model and hold out set as arguments \n",
    "        # store the feature importance of all the features \n",
    "\n",
    "    # average out the feature importance across the folds and get the argmin \n",
    "    # store the no of features \n",
    "    # store the average of the cv scores\n",
    "    # store the standard deviation of the cv scores\n",
    "\n",
    "    # no_of_features to decrease = min(5,curr_no_features-5)\n",
    "    # if(no_of_features to decrease):\n",
    "    #      break\n",
    "    # remove the features from the dataset and continue with the changed dataset \n",
    "\n",
    "# Arguments: df(the dataset features), fold_arr, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_results(df,fold_arr: list,y_arr: list,decrement: int,lower_bound: int,max_iters: int):\n",
    "    results = defaultdict(list)\n",
    "    folds = sorted(fold_arr.unique())\n",
    "    curr_features = list(df.columns)\n",
    "\n",
    "    while len(curr_features) >= lower_bound:\n",
    "        cv_scores = []\n",
    "        feature_importances = []\n",
    "        roc_auc_scores = []\n",
    "        auprc_scores = []\n",
    "\n",
    "        print(\"Current features: \" + str(len(curr_features)))\n",
    "\n",
    "        for fold_val in folds:\n",
    "\n",
    "            # Split data\n",
    "            X_val = df[fold_arr == fold_val][curr_features].to_numpy()\n",
    "            y_val = y_arr[fold_arr == fold_val].to_numpy()\n",
    "\n",
    "            X_train = df[fold_arr != fold_val][curr_features].to_numpy()\n",
    "            y_train = y_arr[fold_arr != fold_val].to_numpy()\n",
    "\n",
    "            # Fit model\n",
    "            model = LogisticRegression(max_iter=max_iters).fit(X_train, y_train)\n",
    "\n",
    "            # get the test out set scores\n",
    "            y_pred = model.predict(X_val)\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            cv_scores.append(acc)\n",
    "\n",
    "            # Permutation importance\n",
    "            perm = permutation_importance(model, X_val, y_val, n_repeats=10, random_state=42)\n",
    "            feature_importances.append(perm.importances_mean)\n",
    "\n",
    "            # Get the probability estimates for the positive class\n",
    "            y_scores = model.predict_proba(X_val)[:, 1]\n",
    "            roc_auc_scores.append(roc_auc_score(y_val,y_scores))\n",
    "            auprc_scores.append(average_precision_score(y_val, y_scores))\n",
    "\n",
    "\n",
    "        # Store results\n",
    "        results['num_features'].append(len(curr_features))\n",
    "        results['cv_score_mean'].append(np.mean(cv_scores))\n",
    "        results['cv_score_std'].append(np.std(cv_scores))\n",
    "        results['roc_auc_score'].append(np.mean(roc_auc_scores))\n",
    "        results['aurpc_score'].append(np.mean(auprc_scores))\n",
    "\n",
    "        # Average feature importance across folds\n",
    "        avg_importance = np.mean(feature_importances, axis=0)\n",
    "        # print(avg_importance)\n",
    "\n",
    "        # Find least important features\n",
    "        num_to_remove = min(decrement, len(curr_features) - lower_bound)\n",
    "        \n",
    "        if num_to_remove == 0:\n",
    "            break\n",
    "\n",
    "        remove_idx = np.argsort(avg_importance)[:num_to_remove]\n",
    "        remove_features = [curr_features[i] for i in remove_idx]\n",
    "\n",
    "        # Remove features for next iteration\n",
    "        # works on feature names....have to ensure feature names are different\n",
    "        curr_features = [f for f in curr_features if f not in remove_features]\n",
    "\n",
    "    # Convert results to DataFrame for inspection\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28962465",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [1,3,7]\n",
    "dfs_arr = create_diff_dfs(df)\n",
    "results_dict = defaultdict(list)\n",
    "no_of_model_features = [5,5,4,5,6]\n",
    "for day in days: \n",
    "    for dataframe_index in range(len(dfs_arr)):\n",
    "        data,fold_arr,y_arr = create_df(dfs_arr[dataframe_index],day)\n",
    "        results = give_results(data,fold_arr,y_arr,5,no_of_model_features[dataframe_index],2000)\n",
    "        results_dict[day].append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef64e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pkl','wb') as file:\n",
    "    # Dump data with highest protocol for best performance\n",
    "    pl.dump(results_dict, file, protocol=pl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85827a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results.pkl', 'rb') as f:\n",
    "        # Load the data from the pickle file\n",
    "        loaded_data = pl.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
