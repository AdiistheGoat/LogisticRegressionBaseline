{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2a5228",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96f4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from collections import defaultdict\n",
    "import pickle as pl\n",
    "import math\n",
    "from sklearn.metrics import (precision_recall_curve,\n",
    "                             PrecisionRecallDisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d81057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ab83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e98a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('papermodeldata(in).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba64a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns) -5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a0039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ttd'].isnull().any()\n",
    "df['fold'].isnull().any()\n",
    "df['time'].isnull().any()\n",
    "df['y'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e8fedcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6785127250348604)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_labels = df['y'].groupby(df['y']).count()\n",
    "count_labels[1]/count_labels[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89199aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VitalID\n",
       "1005     12\n",
       "1007    138\n",
       "1010    267\n",
       "1011     53\n",
       "1013    103\n",
       "       ... \n",
       "8769     13\n",
       "8770      6\n",
       "8771      4\n",
       "8772      8\n",
       "8773      4\n",
       "Name: VitalID, Length: 5957, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['VitalID'].groupby(df['VitalID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef7b54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead = df[df['y'] == 1]\n",
    "df_alive = df[df['y'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7053ddab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VitalID\n",
       "1005     12\n",
       "1007    138\n",
       "1010    265\n",
       "1011     53\n",
       "1013     98\n",
       "       ... \n",
       "8769     13\n",
       "8770      6\n",
       "8771      4\n",
       "8772      8\n",
       "8773      4\n",
       "Name: VitalID, Length: 5948, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alive['VitalID'].groupby(df_alive['VitalID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42cc5724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VitalID\n",
       "1010    2\n",
       "1013    5\n",
       "1017    7\n",
       "1028    3\n",
       "1031    3\n",
       "       ..\n",
       "8364    2\n",
       "8501    1\n",
       "8510    2\n",
       "8521    3\n",
       "8549    5\n",
       "Name: VitalID, Length: 219, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dead['VitalID'].groupby(df_dead['VitalID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ad0ca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674415267613718\n",
      "0.5912786400591279\n",
      "0.5741482208959734\n",
      "0.7453205725417126\n",
      "0.5463627848891663\n",
      "0.7854225573358466\n",
      "0.8354916868577157\n",
      "0.5309466019417476\n",
      "0.6714517249363279\n",
      "0.8686388592968943\n"
     ]
    }
   ],
   "source": [
    "count_folds = df.groupby(['fold','y']).size()\n",
    "first = None\n",
    "second = None\n",
    "count = 0\n",
    "for i in count_folds:\n",
    "    count+=1\n",
    "    if not(first):\n",
    "        first = i\n",
    "    else:\n",
    "        second = i\n",
    "\n",
    "    if(count==2):\n",
    "        count = 0\n",
    "        print((second/first)*100)\n",
    "        first = None \n",
    "        second = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "29727d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(['VitalID', 'time','fold','ttd'], axis=1)\n",
    "df_na_dropped = df_dropped.dropna()\n",
    "df_dead = df_dropped[df_dropped['y'] == 1]\n",
    "df_alive = df_dropped[df_dropped['y'] == 0]\n",
    "df_dead_na_dropped = df_na_dropped[df_na_dropped['y'] == 1]\n",
    "df_alive_na_dropped = df_na_dropped[df_na_dropped['y'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6ba51166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6073478760045925\n",
      "2.0324221579976474\n"
     ]
    }
   ],
   "source": [
    "print(((len(df_dead)- len(df_dead_na_dropped)) /len(df_dead)) * 100)\n",
    "print(((len(df_alive) - len(df_alive_na_dropped)) /len(df_alive))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde131e2",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "44ea594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the y seprate \n",
    "# remove nan values \n",
    "# remove duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d3f9679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if baby remained ill for a long time until his/her death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "197f206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ttd is there , that means the baby is eventually going to die..\n",
    "# if ttd<=days , put y = 1\n",
    "# if ttd>days  , put y =0\n",
    "def format_y(no_of_days,ttd,y_values):\n",
    "    for index in range(len(ttd)):\n",
    "        if(ttd[index]<=no_of_days):\n",
    "            y_values[index] = 1\n",
    "        else:\n",
    "            y_values[index] = 0\n",
    "    return y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f33871e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "def winsorize_col(column):\n",
    "    return winsorize(column, limits=(0.001, .001))\n",
    "\n",
    "def winsorize_df(df):\n",
    "    return df.apply(winsorize_col,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96072373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df,days):\n",
    "    ttd = df['ttd']\n",
    "    y_arr = df['y']\n",
    "    y_arr = format_y(days,ttd,y_arr)\n",
    "    df['y'] = y_arr\n",
    "    # change the y column in the df to the y_arr\n",
    "\n",
    "    # we only care if the trainign data colun values contain NaN values \n",
    "    df_drop_col = df.drop(['VitalID','ttd','time'], axis=1)\n",
    "    df_drop_col_dup = df_drop_col.drop_duplicates()\n",
    "    df_drop_col_dup_na = df_drop_col_dup.dropna()\n",
    "\n",
    "    y_arr = df_drop_col_dup_na['y']\n",
    "    fold_arr = df_drop_col_dup_na['fold']\n",
    "\n",
    "    df_drop_col_dup_na.drop(['y','fold'], axis=1,inplace=True)\n",
    "    df = winsorize_df(df_drop_col_dup_na)\n",
    "    return df,fold_arr,y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f693e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basics = [ \"VitalID\",\"time\",\"fold\",\"ttd\",\"y\"]\n",
    "\n",
    "Demographics = ['bwt', 'ega', 'male', 'apgar5']\n",
    "\n",
    "HR = ['HR.SB.MotifTwo.diff.uu', 'HR.SB.MotifTwo.diff.uuu','HR.ST.LocalExtrema.l25.diffmaxabsmin', 'HR.std','HR.SB.MotifThree.diffquant.hhhh',\n",
    "       'HR.EX.MovingThreshold.a0.25.b0.1.meanqover', 'HR.DN.cv.3','HR.SB.MotifTwo.iqr.ddd','HR.SY.StdNthDer.5','HR.ST.LocalExtrema.l25.maxmaxmed', 'HR.SY.StdNthDer.17', 'HR.Quantile.99', 'HR.FC.Suprise.tstat',\n",
    "       'HR.SB.MotifThree.quantile.hhhh','HR.EX.MovingThreshold.a0.25.b0.05.meanqover','HR.PH.Walkerrunningvar...sw.meanabsdiff', 'HR.CO.tc3.1..denom', 'HR.mean',\n",
    "       'HR.skew2','HR.SB.TransitionMatrix23.sumdiagcov','HR.ST.LocalExtrema.n100.minabsmin', 'HR.kurt2', 'HR.MF.arfit.sbc.7'\n",
    "       ]\n",
    "\n",
    "SPO2 = [ 'SP.EX.MovingThreshold.a0.25.b0.1.meanqover', 'SP.EX.MovingThreshold.a1.b0.25.iqrq', 'SP.PH.Walkerbiasprop.0.1..0.5..sw.meanabsdiff',\n",
    "'SP.EX.MovingThreshold.a0.25.b0.1.maxq', 'SP.PH.Walkerprop.0.9..w.std', 'SP.skew2','SP.SB.MotifTwo.diff.dduu','SP.DN.RemovePointsmin.0.2.mean',\n",
    "'SP.PH.Walkermomentum.2..sw.stdrat','SP.CO.tc3.1..denom','SP.mean','SP.kurt2', 'SP.SB.MotifThree.diffquant.hhh','SP.SB.MotifTwo.mean.dddd',\n",
    "'SP.AutoCorr.lag.4','SP.SB.TransitionMatrix41.ondiag', 'SP.SB.MotifThree.quantile.baaa','SP.std', 'SP.SB.TransitionMatrix21.T10', 'SP.SB.BinaryMethod.iqr.pstretch1'\n",
    ",'SP.PH.Walkerprop.0.9..sw.stdrat','SP.MF.arfit.sbc.7','SP.SB.TransitionMatrix22.mineig','SP.ST.LocalExtrema.n100.minabsmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "13a6b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_dfs(df):\n",
    "    df_hr = df[Basics + HR]\n",
    "    df_spo2 = df[Basics + SPO2]\n",
    "    df_demographics = df[Basics + Demographics]\n",
    "    df_hr_spo2 = df[Basics + HR + SPO2] \n",
    "    df_hr_spo2_demographics = df[Basics + HR + SPO2 + Demographics]\n",
    "    return [df_hr,df_spo2,df_demographics,df_hr_spo2,df_hr_spo2_demographics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "40e1e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_hr,df_spo2,df_demographics,df_hr_spo2,df_hr_spo2_demographics] = create_diff_dfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "82d442ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  y  Count\n",
      "0      1  0  13938\n",
      "1      1  1     94\n",
      "2      2  0  13530\n",
      "3      2  1     80\n",
      "4      3  0  13237\n",
      "5      3  1     76\n",
      "6      4  0  11807\n",
      "7      4  1     88\n",
      "8      5  0  12812\n",
      "9      5  1     70\n",
      "10     6  0  12732\n",
      "11     6  1    100\n",
      "12     7  0  11969\n",
      "13     7  1    100\n",
      "14     8  0  13184\n",
      "15     8  1     70\n",
      "16     9  0  12957\n",
      "17     9  1     87\n",
      "18    10  0  12203\n",
      "19    10  1    106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    fold  y  Count\n",
      "0      1  0  13938\n",
      "1      1  1     94\n",
      "2      2  0  13530\n",
      "3      2  1     80\n",
      "4      3  0  13237\n",
      "5      3  1     76\n",
      "6      4  0  11807\n",
      "7      4  1     88\n",
      "8      5  0  12812\n",
      "9      5  1     70\n",
      "10     6  0  12732\n",
      "11     6  1    100\n",
      "12     7  0  11969\n",
      "13     7  1    100\n",
      "14     8  0  13184\n",
      "15     8  1     70\n",
      "16     9  0  12957\n",
      "17     9  1     87\n",
      "18    10  0  12203\n",
      "19    10  1    106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    fold  y  Count\n",
      "0      1  0  13938\n",
      "1      1  1     94\n",
      "2      2  0  13530\n",
      "3      2  1     80\n",
      "4      3  0  13237\n",
      "5      3  1     76\n",
      "6      4  0  11807\n",
      "7      4  1     88\n",
      "8      5  0  12812\n",
      "9      5  1     70\n",
      "10     6  0  12732\n",
      "11     6  1    100\n",
      "12     7  0  11969\n",
      "13     7  1    100\n",
      "14     8  0  13184\n",
      "15     8  1     70\n",
      "16     9  0  12957\n",
      "17     9  1     87\n",
      "18    10  0  12203\n",
      "19    10  1    106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    fold  y  Count\n",
      "0      1  0  13938\n",
      "1      1  1     94\n",
      "2      2  0  13530\n",
      "3      2  1     80\n",
      "4      3  0  13237\n",
      "5      3  1     76\n",
      "6      4  0  11807\n",
      "7      4  1     88\n",
      "8      5  0  12812\n",
      "9      5  1     70\n",
      "10     6  0  12732\n",
      "11     6  1    100\n",
      "12     7  0  11969\n",
      "13     7  1    100\n",
      "14     8  0  13184\n",
      "15     8  1     70\n",
      "16     9  0  12957\n",
      "17     9  1     87\n",
      "18    10  0  12203\n",
      "19    10  1    106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    fold  y  Count\n",
      "0      1  0  13938\n",
      "1      1  1     94\n",
      "2      2  0  13530\n",
      "3      2  1     80\n",
      "4      3  0  13237\n",
      "5      3  1     76\n",
      "6      4  0  11807\n",
      "7      4  1     88\n",
      "8      5  0  12812\n",
      "9      5  1     70\n",
      "10     6  0  12732\n",
      "11     6  1    100\n",
      "12     7  0  11969\n",
      "13     7  1    100\n",
      "14     8  0  13184\n",
      "15     8  1     70\n",
      "16     9  0  12957\n",
      "17     9  1     87\n",
      "18    10  0  12203\n",
      "19    10  1    106\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [df_hr,df_spo2,df_demographics,df_hr_spo2,df_hr_spo2_demographics]:\n",
    "    print(i.groupby(['fold', 'y']).agg(Count=(\"VitalID\",\"count\")).reset_index())\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e05dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3fbc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while (curr_no_of_features(variable) >= 5)\n",
    "    # for the different no of folds(variable)\n",
    "        # take only that fold dataset from the df(variable) and its corresponding y for validation \n",
    "        # the rest of the data will be used to train the model\n",
    "\n",
    "        # fit the model \n",
    "        # do the inference on the hold out set \n",
    "        # store the cv accuracy score \n",
    "\n",
    "        # call the permuation_importance function and provide the fitted model and hold out set as arguments \n",
    "        # store the feature importance of all the features \n",
    "\n",
    "    # average out the feature importance across the folds and get the argmin \n",
    "    # store the no of features \n",
    "    # store the average of the cv scores\n",
    "    # store the standard deviation of the cv scores\n",
    "\n",
    "    # no_of_features to decrease = min(5,curr_no_features-5)\n",
    "    # if(no_of_features to decrease):\n",
    "    #      break\n",
    "    # remove the features from the dataset and continue with the changed dataset \n",
    "\n",
    "# Arguments: df(the dataset features), fold_arr, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7c8dd072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have uniform logits\n",
    "# write modular code \n",
    "# look at internet examples   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7696d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_logits = 3000\n",
    "base_logit = 1/no_of_logits\n",
    "logits_arr = sorted([base_logit*i for i in range(1,no_of_logits+1)])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a427c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_results(df,fold_arr: list,y_arr: list,decrement: int,lower_bound: int,max_iters: int):\n",
    "    results = defaultdict(list)\n",
    "    folds = sorted(fold_arr.unique())\n",
    "    curr_features = list(df.columns)\n",
    "\n",
    "    while len(curr_features) >= lower_bound:\n",
    "        cv_scores = []\n",
    "        feature_importances = []\n",
    "        roc_auc_scores = []\n",
    "        auprc_scores = []\n",
    "\n",
    "        precisions_arr = []\n",
    "        recalls_arr = []\n",
    "        false_positive_rates_arr = []\n",
    "\n",
    "        print(\"Current features: \" + str(len(curr_features)))\n",
    "\n",
    "        for fold_val in folds:\n",
    "\n",
    "            # Split data\n",
    "            X_val = df[fold_arr == fold_val][curr_features].to_numpy()\n",
    "            y_val = y_arr[fold_arr == fold_val].to_numpy()\n",
    "\n",
    "            X_train = df[fold_arr != fold_val][curr_features].to_numpy()\n",
    "            y_train = y_arr[fold_arr != fold_val].to_numpy()\n",
    "\n",
    "            # Fit model\n",
    "            model = LogisticRegression(max_iter=max_iters).fit(X_train, y_train)\n",
    "\n",
    "            # get the test out set scores\n",
    "            y_pred = model.predict(X_val)\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            cv_scores.append(acc)\n",
    "\n",
    "            # Permutation importance\n",
    "            perm = permutation_importance(model, X_val, y_val, n_repeats=10, random_state=42)\n",
    "            feature_importances.append(perm.importances_mean)\n",
    "\n",
    "            # Get the probability estimates for the positive class\n",
    "            y_scores = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "            roc_auc_scores.append(roc_auc_score(y_val,y_scores))\n",
    "            auprc_scores.append(average_precision_score(y_val, y_scores))\n",
    "\n",
    "            recall_arr = []\n",
    "            precision_arr = []\n",
    "            false_positive_rate_arr = []\n",
    "            y_val = np.array(y_val)\n",
    "\n",
    "            for logit in logits_arr:\n",
    "\n",
    "                y_scores_pred = np.array(y_scores) > logit\n",
    "                true_positives = sum(np.logical_and(y_scores_pred==1,y_val==1))\n",
    "                false_negatives = sum(np.logical_and(y_scores_pred == 0, y_val==1))\n",
    "                false_positives = sum(np.logical_and(y_scores_pred == 1, y_val==0))\n",
    "                true_negatives = sum(np.logical_and(y_scores_pred==0,y_val==0))\n",
    "\n",
    "                recall = true_positives/(true_positives+false_negatives)\n",
    "                precision = true_positives/(true_positives+false_positives)\n",
    "                fpr = false_positives/(false_positives+true_negatives)\n",
    "\n",
    "                if(math.isnan(precision)):\n",
    "                    precision_arr.append(1)\n",
    "                else:\n",
    "                    precision_arr.append(precision)\n",
    "\n",
    "                recall_arr.append(recall)\n",
    "                false_positive_rate_arr.append(fpr)\n",
    "\n",
    "            recalls_arr.append(recall_arr)\n",
    "            precisions_arr.append(precision_arr)\n",
    "            false_positive_rates_arr.append(false_positive_rate_arr)\n",
    "\n",
    "\n",
    "        # Store results\n",
    "        results['num_features'].append(len(curr_features))\n",
    "        results['cv_score_mean'].append(np.mean(cv_scores))\n",
    "        results['cv_score_std'].append(np.std(cv_scores))\n",
    "        results['roc_auc_score'].append(np.mean(roc_auc_scores))\n",
    "        results['aurpc_score'].append(np.mean(auprc_scores))\n",
    "\n",
    "        recalls_arr_mean = np.mean(recalls_arr,axis =0)  # true postive rate = recall\n",
    "        precisions_arr_mean = np.mean(precisions_arr,axis =0)\n",
    "        false_positive_rates_arr_mean = np.mean(false_positive_rates_arr,axis=0)\n",
    "\n",
    "        recall_arr_std = np.std(recalls_arr,axis=0)\n",
    "        precision_arr_std = np.std(precisions_arr,axis=0)\n",
    "        false_positive_rate_arr_std = np.std(false_positive_rates_arr,axis=0)\n",
    "\n",
    "        results['recalls_arr_mean'].append(recalls_arr_mean)\n",
    "        results['precisions_arr_mean'].append(precisions_arr_mean)\n",
    "        results['false_positive_rates_arr_mean'].append(false_positive_rates_arr_mean)\n",
    "        results['recall_arr_std'].append(recall_arr_std)\n",
    "        results['precision_arr_std'].append(precision_arr_std)\n",
    "        results['false_positive_rate_arr_std'].append(false_positive_rate_arr_std)\n",
    "\n",
    "\n",
    "        # Average feature importance across folds\n",
    "        avg_importance = np.mean(feature_importances, axis=0)\n",
    "        # print(avg_importance)\n",
    "\n",
    "        # Find least important features\n",
    "        num_to_remove = min(decrement, len(curr_features) - lower_bound)\n",
    "        \n",
    "        if num_to_remove == 0:\n",
    "            break\n",
    "\n",
    "        remove_idx = np.argsort(avg_importance)[:num_to_remove]\n",
    "        remove_features = [curr_features[i] for i in remove_idx]\n",
    "\n",
    "        # Remove features for next iteration\n",
    "        # works on feature names....have to ensure feature names are different\n",
    "        curr_features = [f for f in curr_features if f not in remove_features]\n",
    "\n",
    "    # Convert results to DataFrame for inspection\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28962465",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [7,3,1]\n",
    "dfs_arr = create_diff_dfs(df)\n",
    "results_dict = defaultdict(list)\n",
    "no_of_model_features = [5,5,4,5,6] # specifying the lower bound\n",
    "decrement = 5  # specifying the no of features to decrement by every time\n",
    "\n",
    "for day in days: \n",
    "    for dataframe_index in range(len(dfs_arr)):\n",
    "        data,fold_arr,y_arr = create_df(dfs_arr[dataframe_index],day)\n",
    "        results = give_results(data,fold_arr,y_arr,decrement,no_of_model_features[dataframe_index],2000)\n",
    "        results_dict[day].append(results)\n",
    "        break\n",
    "    break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d264eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results2.pkl', 'wb') as f:\n",
    "        # Load the data from the pickle file\n",
    "        pl.dump(results_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85827a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results1.pkl', 'rb') as f:\n",
    "        # Load the data from the pickle file\n",
    "        loaded_data = pl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "03407ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/Users/adityagoyal/Desktop/Research - yin li/baseline/results2'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "for day in days: \n",
    "    # create dir for day\n",
    "    \n",
    "    output_dir = '/Users/adityagoyal/Desktop/Research - yin li/baseline/results2'\n",
    "    filename = f\"Day: {day}\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    if not os.path.isdir(filepath):\n",
    "        os.makedirs(filepath)\n",
    "    \n",
    "    \n",
    "    for dataframe_index in range(len(dfs_arr)):\n",
    "        \n",
    "        # create dir for dataframe_index..this is the last dir\n",
    "        output_dir = f'/Users/adityagoyal/Desktop/Research - yin li/baseline/results2/Day: {day}'\n",
    "        filename = f\"df: {dataframe_index}\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        if not os.path.isdir(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        \n",
    "        \n",
    "        result = loaded_data[day][dataframe_index]\n",
    "\n",
    "        x_precisions = np.array(result['precisions_arr_mean'])\n",
    "        x_recalls = np.array(result['recalls_arr_mean'])\n",
    "        x_fprs = np.array(result['false_positive_rates_arr_mean'])\n",
    "        \n",
    "        x_precision_stds = np.array(result['precision_arr_std'])\n",
    "        x_recall_stds = np.array(result['recall_arr_std'])\n",
    "        x_fpr_stds = np.array(result['false_positive_rate_arr_std'])\n",
    "        \n",
    "        roc_auc_scores = result['roc_auc_score']\n",
    "        aurpc_scores = result['aurpc_score']\n",
    "        num_features = result['num_features']\n",
    "        \n",
    "        for feature_index in range(len(x_fpr_stds)):\n",
    "\n",
    "            output_dir = f'/Users/adityagoyal/Desktop/Research - yin li/baseline/results2/Day: {day}/df: {dataframe_index}'\n",
    "            filename = f\"no_of_features: {num_features[feature_index]}\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            if not os.path.isdir(filepath):\n",
    "                os.makedirs(filepath)\n",
    "            \n",
    "            x_precision = x_precisions[feature_index]\n",
    "            x_recall = x_recalls[feature_index]\n",
    "            x_fpr = x_fprs[feature_index]\n",
    "            \n",
    "            x_precision_std = x_precision_stds[feature_index]\n",
    "            x_recall_std = x_recall_stds[feature_index]\n",
    "            x_fpr_std = x_fpr_stds[feature_index] \n",
    "            \n",
    "            roc_auc_score = roc_auc_scores[feature_index]\n",
    "            aurpc_score = aurpc_scores[feature_index]\n",
    "        \n",
    "            plt.plot(x_recall,x_precision, color=\"blue\")\n",
    "            plt.xlim(0,1)\n",
    "            plt.ylim(0,1)\n",
    "            lower = np.maximum(x_precision - x_precision_std, 0.0).reshape(-1)\n",
    "            upper = np.minimum(x_precision + x_precision_std, 1.0).reshape(-1)\n",
    "            plt.fill_between(x_recall.reshape(-1), lower, upper, alpha=0.3,color='0.8')\n",
    "            plt.text(0.5, 0.5, f'Aurpc score: {int(aurpc_score*1000)/1000}', fontsize=12, color='red')\n",
    "            plt.xlabel(\"Recall\")\n",
    "            plt.ylabel(\"Precision\")\n",
    "            plt.legend()\n",
    "            plt.title(\"Precision Recall curve\")\n",
    "            plt.savefig(f\"{filepath}/PR curve.png\", dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            plt.plot(x_fpr,x_recall, color=\"blue\")\n",
    "            plt.xlim(0,1)\n",
    "            plt.ylim(0,1)\n",
    "            lower = np.maximum(x_recall - x_recall_std, 0.0).reshape(-1)\n",
    "            upper = np.minimum(x_recall + x_recall_std, 1.0).reshape(-1)\n",
    "            plt.fill_between(x_fpr.reshape(-1), lower, upper, alpha=0.3,color='0.8')\n",
    "            plt.text(0.5, 0.5, f'ROC-AUC score: {int(roc_auc_score*1000)/1000}', fontsize=12, color='red')\n",
    "            plt.xlabel(\"FPR\")\n",
    "            plt.ylabel(\"Recall\")\n",
    "            plt.legend()\n",
    "            plt.title(\"ROC-AUC curve\")\n",
    "            plt.savefig(f\"{filepath}/ROC-AUC curve.png\", dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        break\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision is basically out of all the datapoints you predicted as a class, how much of that is correct.\n",
    "# Recall is basically, out of all the datapoints belonging to that class, how much were you able to predict correctly.\n",
    "# You can get this intuition for either of the classes, especially for the imbalanced class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d52b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08106467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive and negative are the two classes\n",
    "# The true positive rate is a measure of the probability that an actual positive instance will be classified as positive.\n",
    "# The true negative rate is a measure of the probability that an actual negative instance will be classified as negative. \n",
    "# he false positive rate is essentially a measure of how often a \"false alarm\" will occur – or, how often an actual negative instance will be classified as positive. (actually this metric says inofrmation aboput the other class!!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = tp/(tp+fp)\n",
    "# recall = tp/(tp + fn)  (also known as the true positive rate)\n",
    "# f1 = 2*precision*recall/ (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we talk about metrics we talk about only pertaining to one class\n",
    "# true positive rate = tp/(tp + fn) \n",
    "# false positive rate = fp(falsely predicted negative datapoints)/fp+tn (all the negative datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eac931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your use case determines how much importance you give to partiuclar evaluation metrics and which evluation metrics you use and on which class - the 0 or the 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8951919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each fold(hold out set): \n",
    "    # Get the predicted logits\n",
    "    # figure out the different values of the boundary logits (from 0 to 1) say k (like randomly generate unformly spaced values)\n",
    "    # get the precision recall values for each of the boundary logits \n",
    "\n",
    "# average out the precision scores at a particualr boundary logit across the various folds \n",
    "# average out the recall scores at a particualr boundary logit across the various folds \n",
    "# take the stadnard deviation of the precision socres at a particualr boundary logit across the various folds \n",
    "# take the stadnard deviation of the recall socres at a particualr boundary logit across the various folds \n",
    "\n",
    "# shape of the precision scores: (folds,k)\n",
    "# shape of the recall curves: (folds,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each fold(hold out set): \n",
    "    # Get the predicted logits\n",
    "    # figure out the different values of the boundary logits (from 0 to 1) say k (like randomly generate unformly spaced values)\n",
    "    # get the tpr and fpr values for each of the boundary logits \n",
    "\n",
    "# average out the tpr socres at a particualr boundary logit across the various folds \n",
    "# average out the fpr scores at a particualr boundary logit across the various folds \n",
    "# take the stadnard deviation of the tpr socres at a particualr boundary logit across the various folds \n",
    "# take the stadnard deviation of the fpr socres at a particualr boundary logit across the various folds \n",
    "\n",
    "# shape of the tpr scores: (folds,k)\n",
    "# shape of the fpr curves: (folds,k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
